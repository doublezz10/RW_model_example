{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rescorla-Wagner Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doublezz10/RW_model_example/blob/main/Rescorla_Wagner_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDM1cs0NOoM7"
      },
      "source": [
        "# **Reinforcement learning: How to model \"gambling\" behavior**\n",
        "Zach Zeisler\n",
        "\n",
        "Rudebeck Lab - CEYE Day 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iAHCsj0QtNg"
      },
      "source": [
        "**Who am I?**\n",
        "\n",
        "I'm starting the fourth year of my PhD in the Rudebeck Lab. Right now, my project is focused on optimizing MAPseq (a super cool way to study brain anatomy that I'll talk about this afternoon) for use in non-human primates. I'm broadly interested in the structural basis of cognition, comparative neuroanatomy, and how amygdala and prefrontal cortex are critical for the computations that underlie complex behaviors - like we'll be talking about today!\n",
        "\n",
        "Here's my [email](mailto:zach.zeisler@icahn.mssm.edu) and my [Twitter](https://twitter.com/zachzeisler1) if you're interested in connecting with me!\n",
        "\n",
        "\n",
        "![my headshot](https://icahn.mssm.edu/files/fad_img_new/255/0000076810083888249091/0000072500078348997201.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-5qBtDsdYM"
      },
      "source": [
        "# Behavioral modelling - rationale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90TKs-8qg4X"
      },
      "source": [
        "We talked briefly during Pete's lecture about how the amygdala is involved in processing rewards and guiding behavior to maximize them. In this short exercise, we'll explore a task designed to study this kind of decision making behavior, introduce the concept of computational modelling, and build our own simple reinforcement model to closely study some real behavioral data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC7DkyGS6M11"
      },
      "source": [
        "First, a brief reminder of what **prediction errors** are:\n",
        "\n",
        "![prediction errors](https://i.ibb.co/Ypdc97H/predictionerror.png)\n",
        "\n",
        "The brain is constantly making predictions about the world. Sometimes these predictions are correct, but often times, they aren't (like in the cartoon above). In these cases where the outcome is not what we had expected, we need to update our predictions, so that in future scenarios, we have a better chance of making the correct prediction.\n",
        "\n",
        "**Prediction error** is the brain's way of calculating how different the real world is from what we expected. But, it is not optimal to totally change our expectations based on only one exposure; rather, it should take multiple times seeing bears behind trees to assume that behind every tree there is a bear. This is where the concept of **learning rate** comes into the equation. One way to think about learning rate is that it is how important each exposure is. Higher learning rate means that it would take fewer instances of seeing bears to assume that all trees have bears behind them. These two factors go into an equation called the Rescorla-Wagner Model to allow us to predict someone's new expectation based on prior experiences. A simplified equation for the model is below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE2O9BE3Jjxi"
      },
      "source": [
        "\n",
        "$New Expectation = Old Expectation + (Learning Rate * Prediction Error)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-G50vvapC-3"
      },
      "source": [
        "## Task design\n",
        "\n",
        "We're going to provide you with some data to explore. The data was collected from a task like this. Participants are allowed to choose one of three slot machines; each one has a different chance of giving out a reward (pretend that there are only two outcomes: win or lose). The participants' goal is to learn (by trial-and-error) which choices give them the highest chance of a reward, and gather as many rewards as possible over 300 trials. The best option switches at some point during the experiment (called a reversal), so participants must constantly adapt in order to succeed. We're going to look at data from one participant playing this game, and see what we can discover about learning and decision making.\n",
        "\n",
        "![task design](https://i.ibb.co/JydtCpN/slots.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opn7VZFqMP_I"
      },
      "source": [
        "# Download data, prepare to analyze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXh7q5duhCgo"
      },
      "source": [
        "This is a Python notebook - there's a lot of code buried under the titles below, but you dont need to worry about that :) \n",
        "\n",
        "Below are a couple of cells to get the simulation up and running; simply click the play button (which will appear if you hover over the [   ]'s) to the left of each cell in order to run it. These first couple may take a little while to run as we download and format the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGI_VWOEdVsd",
        "cellView": "form"
      },
      "source": [
        "#@title Set up programming environment\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import ipywidgets as widgets       # interactive display\n",
        "from ipywidgets import interact, interact_manual\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "# import data\n",
        "\n",
        "trial_choice_reward = np.genfromtxt(\"https://raw.githubusercontent.com/doublezz10/RW_model_example/main/trial_choice_reward.csv\",delimiter=',')\n",
        "trial_choice_reward[0,0] = 1\n",
        "\n",
        "ntrials = 300\n",
        "noptions = 3\n",
        "\n",
        "# calculate choice matrix\n",
        "choice_1 = np.zeros((300,1))\n",
        "choice_2 = np.zeros((300,1))\n",
        "choice_3 = np.zeros((300,1))\n",
        "\n",
        "for i in range(ntrials):\n",
        "\n",
        "  if trial_choice_reward[i,1] == 1:\n",
        "    choice_1[i,0]=1\n",
        "  else: \n",
        "    choice_1[i,0]=0\n",
        "\n",
        "  if trial_choice_reward[i,1] == 2:\n",
        "    choice_2[i,0]=1\n",
        "  else:\n",
        "    choice_2[i,0]=0\n",
        "\n",
        "  if trial_choice_reward[i,1] == 3:\n",
        "    choice_3[i,0]=1\n",
        "  else:\n",
        "    choice_3[i,0]=0\n",
        "\n",
        "choices_together = np.hstack((choice_1,choice_2,choice_3))\n",
        "\n",
        "# calculate choice rates (over 10 trials)\n",
        "choice_1_rate = np.zeros((300,1))\n",
        "choice_2_rate = np.zeros((300,1))\n",
        "choice_3_rate = np.zeros((300,1))\n",
        "\n",
        "for j in range(ntrials):\n",
        "  choice_1_rate[j,0] = np.mean(choice_1[j:j+9])\n",
        "  choice_2_rate[j,0] = np.mean(choice_2[j:j+9])\n",
        "  choice_3_rate[j,0] = np.mean(choice_3[j:j+9])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10tjCfN7IGNA",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66bf0b4-d796-45ec-c945-ad4b9b3073a3"
      },
      "source": [
        "#@title What do the data look like?\n",
        "#@markdown Run this cell to show the first 5 rows (trials) of the data. The first column is the trial number, the second column is the choice the participant made on that trial, and the third column is whether or not they were rewarded for that choice. This will be the basis for all of our analysis.\n",
        "\n",
        "print(trial_choice_reward[:5,:])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 3. 0.]\n",
            " [2. 1. 1.]\n",
            " [3. 3. 0.]\n",
            " [4. 3. 0.]\n",
            " [5. 3. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKyfIMpw6dUt"
      },
      "source": [
        "# Basic stats - are they helpful?\n",
        "\n",
        "Here, we'll plot some simple statistics from the data and see what we can learn from them. Press the play button to generate some graphs and think about what they mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vP6OaOFIiMs",
        "cellView": "form"
      },
      "source": [
        "#@title Choices by trial\n",
        "#@markdown Can you estimate when the reversal occurred? Around which trial?\n",
        "\n",
        "plt.figure(figsize=(8,3))\n",
        "plt.xlabel('trial number')\n",
        "plt.ylabel('choice')\n",
        "plt.yticks((1,2,3))\n",
        "plt.scatter(range(ntrials),trial_choice_reward[:,1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLb_u8OZ6g61",
        "cellView": "form"
      },
      "source": [
        "#@title Choice frequency\n",
        "#@markdown How many times did the participant make each choice? Does this tell us which choice is best?\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.bar([0,1,2],(np.sum(choice_1),np.sum(choice_2),np.sum(choice_3)),color=['darkblue','darkgreen','darkred'])\n",
        "plt.xticks((0,1,2),('choice 1','choice 2','choice 3'))\n",
        "plt.ylabel('number of choices');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0jcnFv68j2t",
        "cellView": "form"
      },
      "source": [
        "#@title Reward frequency\n",
        "#@markdown Which choice led to the most rewards (on average)? Is this helpful to know?\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "reward_choice_1 = []\n",
        "reward_choice_2 = []\n",
        "reward_choice_3 = []\n",
        "\n",
        "for i in range(ntrials):\n",
        "  if trial_choice_reward[i,1] == 1:\n",
        "    if trial_choice_reward[i,2] == 1:\n",
        "      reward_choice_1.append(1)\n",
        "    else:\n",
        "      reward_choice_1.append(0)\n",
        "  elif trial_choice_reward[i,1] == 2:\n",
        "    if trial_choice_reward[i,2] == 1:\n",
        "      reward_choice_2.append(1)\n",
        "    else:\n",
        "      reward_choice_2.append(0)\n",
        "\n",
        "  elif trial_choice_reward[i,1] == 3:\n",
        "    if trial_choice_reward[i,2] == 1:\n",
        "      reward_choice_3.append(1)\n",
        "    else:\n",
        "      reward_choice_3.append(0)\n",
        "\n",
        "plt.bar([0,1,2],[np.mean(reward_choice_1),np.mean(reward_choice_2),np.mean(reward_choice_3)],color=['darkblue','darkgreen','darkred'])\n",
        "plt.xticks((0,1,2),('choice 1','choice 2','choice 3'))\n",
        "plt.ylabel('percentage reward');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PqGPmYJKWPV"
      },
      "source": [
        "## Pause here for discussion\n",
        "While these kinds of figures can give us a basic intuition of how the task works, they don't tell us anything about how the participant is learning the task, nor how they are deciding which option to choose. We'll need to do some more complicated analysis to look into these things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omDxp3IsYMk"
      },
      "source": [
        "# Let's make a model!\n",
        "Now, we'll implement a model to see what is happening on a trial-by-trial basis (this model is called a Rescorla-Wagner Model if you're curious to learn more)! This model computes a **prediction error** (how different is the outcome compared to what I was expecting) and multiplies it by a **learning rate** to update an estimation of the true value.\n",
        "\n",
        "Use this cell below to alter the learing rate. Type any value between 0 and 1, and *remember to run the cell* after changing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NAQHCZ_pTRu"
      },
      "source": [
        "learning_rate = 0.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmfINGzBsjWp",
        "cellView": "form"
      },
      "source": [
        "#@title Initiate the model and plot the data!\n",
        "#@markdown *Re-run this cell every time you change the learning rate*\n",
        "\n",
        "#@markdown The plot on the left shows the rate that the participant chooses each option, and the plot on the right shows the predicted value of each choice.\n",
        "\n",
        "#@markdown Try adjusting the learning rate and seeing how the plots change - can you figure out what the learning rate is doing? What is the best value? Try to maximize the percentage of \"correct\" choices.\n",
        "\n",
        "choice_1_value = np.zeros((300,1))\n",
        "choice_2_value = np.zeros((300,1))\n",
        "choice_3_value = np.zeros((300,1))\n",
        "for i in range((ntrials-1)):\n",
        "  if choice_1[i] == 1:\n",
        "    new_value = choice_1_value[i] + learning_rate*(trial_choice_reward[i,2]-choice_1_value[i])\n",
        "  else:\n",
        "    new_value = choice_1_value[i]\n",
        "  choice_1_value[i+1] = new_value\n",
        "\n",
        "  if choice_2[i] == 1:\n",
        "    new_value = choice_2_value[i] + learning_rate*(trial_choice_reward[i,2]-choice_2_value[i])\n",
        "  else:\n",
        "    new_value = choice_2_value[i]\n",
        "  choice_2_value[i+1] = new_value\n",
        "\n",
        "  if choice_3[i] == 1:\n",
        "    new_value = choice_3_value[i] + learning_rate*(trial_choice_reward[i,2]-choice_3_value[i])\n",
        "  else:\n",
        "    new_value = choice_3_value[i]\n",
        "  choice_3_value[i+1] = new_value\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(12,6))\n",
        "ax1.plot(range(ntrials),choice_1_rate,label='choice 1')\n",
        "ax1.plot(range(ntrials),choice_2_rate,label='choice 2')\n",
        "ax1.plot(range(ntrials),choice_3_rate,label='choice 3')\n",
        "ax1.set_xlabel('Trial number')\n",
        "ax1.set_ylabel('Rate')\n",
        "ax1.set_title('Choices')\n",
        "\n",
        "ax2.plot(range(ntrials), choice_1_value,label='choice 1')\n",
        "ax2.plot(range(ntrials), choice_2_value,label ='choice 2')\n",
        "ax2.plot(range(ntrials), choice_3_value,label ='choice 3')\n",
        "ax2.set_xlabel('Trial number')\n",
        "ax2.set_ylabel('Value')\n",
        "ax2.set_title('Modelled Values')\n",
        "ax2.legend();\n",
        "\n",
        "value_by_trial = np.zeros((300,3))\n",
        "max_val_choice = []\n",
        "for trial in range(ntrials):\n",
        "  value_by_trial[trial,0] = choice_1_value[trial]\n",
        "  value_by_trial[trial,1] = choice_2_value[trial]\n",
        "  value_by_trial[trial,2] = choice_3_value[trial]\n",
        "  max_val_choice.append(np.argmax(value_by_trial[trial,:]))\n",
        "\n",
        "best_choice = []\n",
        "for trial in range(ntrials):\n",
        "  if choices_together[trial,max_val_choice[trial]] == 1:\n",
        "    best_choice.append(1)\n",
        "  else:\n",
        "    best_choice.append(0)\n",
        "print('The participant made the best choice', \"%.2f\" % (np.mean(best_choice)*100),'% of the time.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgZIdDeMuQP"
      },
      "source": [
        "## Pause here for discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7DBOAkNyRfZ",
        "cellView": "form"
      },
      "source": [
        "#@title Let's find the best learning rate\n",
        "#@markdown Instead of manually trying every single learning rate, we can compute the accuracy for 1000 values between 0 and 1 and see which has the highest accuracy. This is the power of computation (this will take a minute to calculate, don't worry if it seems slow)! This way, we'll have the \"true\" learning rate that best explains our participant's behavior.\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for rates in np.linspace(0,1,1000):\n",
        "  choice_1_val = np.zeros((300,1))\n",
        "  choice_2_val = np.zeros((300,1))\n",
        "  choice_3_val = np.zeros((300,1))\n",
        "  for i in range((ntrials-1)):\n",
        "    if choice_1[i] == 1:\n",
        "      new_val1 = choice_1_val[i] + rates*(trial_choice_reward[i,2]-choice_1_val[i])\n",
        "    else:\n",
        "      new_val1 = choice_1_val[i]\n",
        "    choice_1_val[i+1] = new_val1\n",
        "\n",
        "    if choice_2[i] == 1:\n",
        "      new_va2l = choice_2_val[i] + rates*(trial_choice_reward[i,2]-choice_2_val[i])\n",
        "    else:\n",
        "      new_val2 = choice_2_val[i]\n",
        "    choice_2_val[i+1] = new_val2\n",
        "\n",
        "    if choice_3[i] == 1:\n",
        "      new_val3 = choice_3_val[i] + rates*(trial_choice_reward[i,2]-choice_3_val[i])\n",
        "    else:\n",
        "      new_val3 = choice_3_val[i]\n",
        "    choice_3_val[i+1] = new_val3\n",
        "\n",
        "  val_by_trial = np.zeros((300,3))\n",
        "  max_val_choices = []\n",
        "  for trial in range(ntrials):\n",
        "    val_by_trial[trial,0] = choice_1_val[trial]\n",
        "    val_by_trial[trial,1] = choice_2_val[trial]\n",
        "    val_by_trial[trial,2] = choice_3_val[trial]\n",
        "    max_val_choices.append(np.argmax(val_by_trial[trial,:]))\n",
        "\n",
        "  best_choices = []\n",
        "  for trial in range(ntrials):\n",
        "    if choices_together[trial,max_val_choices[trial]] == 1:\n",
        "      best_choices.append(1)\n",
        "    else:\n",
        "      best_choices.append(0)\n",
        "  accuracy = np.mean(best_choices)\n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('percent \"best\" option chosen')\n",
        "plt.plot(np.linspace(0,1,1000),accuracies);\n",
        "print('The best learning rate is', \"%.2f\" % np.linspace(0,1,1000)[np.argmax(accuracies)])\n",
        "print('The accuracy of that learning rate is',\"%.2f\" % np.max(accuracies))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH5AqRUpCYS7"
      },
      "source": [
        "## Discussion questions\n",
        "\n",
        "How do you think Patient SM would perform on this task? What would her learning rate be (would it be high or low)?\n",
        "\n",
        "How can you explain the shape of the last graph? (ie why does it go up at first, then go back down)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ug04zg_MYw8"
      },
      "source": [
        "# What do we do with all of this?\n",
        "\n",
        "I hope it's clear that using modelling techniques can give us much more insight into behavior and learning than simple analyses. But where do we go from here?\n",
        "\n",
        "Remember that all of this data and analysis is based on **one** experiment and **one** participant. Imagine if the participant did this same task again: would they be better or worse? Imagine that we compared this participant's performance to other participants' - we could see how different factors affect one's learning rate.\n",
        "\n",
        "If we were to run this experiment on animals and not humans, we could see how different experimental manipualtions affect their performance. We could also study their neural activity (in a variety of ways), to understand what different parts of the brain are doing during this task.\n",
        "\n",
        "The possibilities for follow-up studies are nearly endless! This is why computational models (like this simple Rescorla-Wagner example) are so useful. It's also why they're so widely implemented across different fields of neuroscience and computer science. In fact, Amazon and Netflix use models very similar to this one, albeit a bit more complicated, to recommend you products to buy and shows to watch\n",
        "\n",
        "I hope this was interesting! You can save this exercise to your own Google Drive if you ever want to look back it (go to File/Save a Copy in Drive), and feel free to reach out if you have questions or want to learn more!\n",
        "\n",
        "![Rudebeck Lab ice skating outing at Bryant Park, December 2021](https://i.ibb.co/rwH1TTf/IMG-5458.jpg)"
      ]
    }
  ]
}